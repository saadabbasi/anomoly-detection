import os
import tensorflow as tf
import numpy as np
import os
from time import perf_counter_ns
import argparse

def benchmark_tf_model_ns(sess, OUTPUT_TENSOR, feed_dict, N = 100):
    time_t = np.zeros((N,))
    for n in range(N):
        start_t = perf_counter_ns()
        out = sess.run([OUTPUT_TENSOR], feed_dict = feed_dict)
        end_t = perf_counter_ns()
        time_t[n] = end_t - start_t

    return time_t.min()

def load_graph(meta_graph_file):
    graph = tf.Graph()
    with graph.as_default():
        sess_config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)
        sess = tf.Session(config=sess_config)
        saver = tf.train.import_meta_graph(meta_graph_file)
    return graph, sess, saver

def load_ckpt(sess, saver, ckpt_file):
    saver.restore(sess, tf.train.latest_checkpoint(ckpt_file))

def get_flops(sess, run_meta):
    opts = tf.profiler.ProfileOptionBuilder.float_operation()    
    flops = tf.profiler.profile(sess.graph, run_meta=run_meta, cmd='op', options=opts)

    opts = tf.profiler.ProfileOptionBuilder.trainable_variables_parameter()    
    params = tf.profiler.profile(sess.graph, run_meta=run_meta, cmd='op', options=opts)

    print("{:,} --- {:,}".format(flops.total_float_ops, params.total_parameters))

def decode_model_path(model_dir):
    gensynth_trial_id = os.path.split(model_dir)[1].split("-")[0]
    return gensynth_trial_id

def measure_latency_ns(model_dir, n_iterations = 10):
    gensynth_trial_id = decode_model_path(model_dir)
    macro_arch = gensynth_trial_id.split("_")[1]
    print(gensynth_trial_id,macro_arch)

    IMAGE_INPUT_TENSOR = "input_1:0"
    LOSS_TENSOR = "loss/mul:0"
    if macro_arch == 'SC':
        TARGET_INPUT_TENSOR = "conv2d_6_target:0"
        OUTPUT_TENSOR = "conv2d_6/BiasAdd:0"
    elif macro_arch == 'B':
        TARGET_INPUT_TENSOR = "conv2d_transpose_4_target:0"
        OUTPUT_TENSOR = "conv2d_transpose_4/BiasAdd:0"
    elif macro_arch == 'D':
        TARGET_INPUT_TENSOR = "conv2d_10_target:0"
        OUTPUT_TENSOR = "conv2d_10/BiasAdd:0"
    elif macro_arch == 'DW':
        TARGET_INPUT_TENSOR = "separable_conv2d_6_target:0"
        OUTPUT_TENSOR = "separable_conv2d_6/BiasAdd:0"
    else:
        raise ValueError(f"{macro_arch} not recognized. Is your directory structure and name OK?")

    
    meta_path = os.path.join(model_dir, "model.meta")
    ckpt_path = model_dir
    frozen_path = os.path.join(model_dir, "frozen.pb")

    feed_dict = {IMAGE_INPUT_TENSOR: np.random.rand(1,32,128,1)}
    run_meta = tf.RunMetadata()
    graph,sess,saver = load_graph(meta_path)

    with sess.as_default():
        load_ckpt(sess, saver, ckpt_path)
        tf_min = benchmark_tf_model_ns(sess, OUTPUT_TENSOR, feed_dict, N = n_iterations)

    return {'tensorflow':tf_min}


if __name__ == "__main__":
    os.environ["CUDA_VISIBLE_DEVICES"] = "0"
    parser = argparse.ArgumentParser()
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument('--mdir', action='store', dest="model_dir")
    group.add_argument('--mpath', action='store', dest="model_path")
    args = parser.parse_args()

    print(f"Loading all models from {args.model_dir}")
    models = [os.path.join(args.model_dir,name) for name in os.listdir(args.model_dir) if os.path.isdir(os.path.join(args.model_dir,name))]
    print(models)
    with open("results.txt","w") as f:
        f.write("Trial ID, openvino latency (us), tensorflow latency (us)\n")
        for dir in models:
            print(f"Measuring model in {dir}")
            latency = measure_latency_ns(dir,n_iterations = 100)
            gensynth_trial_id = decode_model_path(dir)
            f.write(f"{gensynth_trial_id},{latency['openvino']/1e6},{latency['tensorflow']/1e6}\n")

    print("========RESULTS=========")
    print(f"Openvino: {openvino_t/1e6} µs")
    print(f"Tensorflow: {tf_t/1e6} µs")
    print("========================")
    
